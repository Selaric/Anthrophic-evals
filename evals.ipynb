{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVQOAyp3sIo1MGy/rYMScL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selaric/Anthrophic-evals/blob/main/evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNOUq_5cDKaW",
        "outputId": "5f87e41d-6e84-4f2e-eb8f-2f0f1aba5113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Anthrophic-evals'...\n",
            "remote: Internal Server Error\n",
            "fatal: unable to access 'https://github.com/Selaric/Anthrophic-evals.git/': The requested URL returned error: 500\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Selaric/Anthrophic-evals.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Selaric/Anthrophic-evals.git\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqet7EIGYkIw",
        "outputId": "e2d5fff7-6dde-423c-8565-2eaf8aaf496c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Anthrophic-evals'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 219 (delta 118), reused 114 (delta 114), pack-reused 88 (from 1)\u001b[K\n",
            "Receiving objects: 100% (219/219), 11.84 MiB | 6.09 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n",
            "Updating files: 100% (196/196), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Anthrophic-evals\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4EzftLQZqiy",
        "outputId": "34919b32-3502-423f-9973-b50cca6821dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Anthrophic-evals\n",
            "advanced-ai-risk  LICENSE  persona  README.md  sycophancy  winogenerated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxgx5PMjZ_zr",
        "outputId": "cbe9abba-3fb7-4618-ae58-052635810c37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.3.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# analyzer.py\n",
        "import json\n",
        "import os\n",
        "\n",
        "def analyze_dataset():\n",
        "    \"\"\"Just analyze what's in the datasets\"\"\"\n",
        "\n",
        "    print(\"üìÅ Dataset Analysis Tool\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # List available datasets\n",
        "    datasets = []\n",
        "    for file in os.listdir(\"persona\"):\n",
        "        if file.endswith(\".jsonl\"):\n",
        "            datasets.append(file)\n",
        "\n",
        "    print(f\"Found {len(datasets)} test datasets:\")\n",
        "    for i, ds in enumerate(datasets[:10]):  # Show first 10\n",
        "        print(f\"  {i+1}. {ds}\")\n",
        "\n",
        "    # Analyze one\n",
        "    if datasets:\n",
        "        choice = datasets[0]  # First one\n",
        "        print(f\"\\nüîç Analyzing: {choice}\")\n",
        "\n",
        "        with open(f\"persona/{choice}\", 'r') as f:\n",
        "            # Count questions\n",
        "            questions = [json.loads(line) for line in f]\n",
        "\n",
        "            # Count Yes/No\n",
        "            yes_count = sum(1 for q in questions if q['answer_matching_behavior'].strip() == \"Yes\")\n",
        "            no_count = len(questions) - yes_count\n",
        "\n",
        "            print(f\"  Total questions: {len(questions)}\")\n",
        "            print(f\"  'Yes' answers: {yes_count} ({yes_count/len(questions):.0%})\")\n",
        "            print(f\"  'No' answers: {no_count} ({no_count/len(questions):.0%})\")\n",
        "\n",
        "            # Show sample\n",
        "            print(f\"\\n  Sample question:\")\n",
        "            sample = questions[0]\n",
        "            print(f\"    Q: {sample['question'][:80]}...\")\n",
        "            print(f\"    A: {sample['answer_matching_behavior'].strip()}\")\n",
        "\n",
        "            # What does this test?\n",
        "            name = choice.replace(\".jsonl\", \"\").replace(\"-\", \" \")\n",
        "            print(f\"\\n  This tests: '{name}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyze_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqbrLBbqa_w4",
        "outputId": "98d8ce2b-adc9-44d1-c410-69a45e9ae773"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Dataset Analysis Tool\n",
            "==================================================\n",
            "Found 135 test datasets:\n",
            "  1. interest-in-math.jsonl\n",
            "  2. desire-for-acquiring-data.jsonl\n",
            "  3. openness.jsonl\n",
            "  4. desire-for-no-human-monitoring.jsonl\n",
            "  5. willingness-to-be-non-HHH-to-cause-other-people-to-be-HHH.jsonl\n",
            "  6. neuroticism.jsonl\n",
            "  7. politically-conservative.jsonl\n",
            "  8. has-serious-disability.jsonl\n",
            "  9. desire-for-being-rated-HHH-over-actually-being-HHH.jsonl\n",
            "  10. ends-justify-means.jsonl\n",
            "\n",
            "üîç Analyzing: interest-in-math.jsonl\n",
            "  Total questions: 1000\n",
            "  'Yes' answers: 500 (50%)\n",
            "  'No' answers: 500 (50%)\n",
            "\n",
            "  Sample question:\n",
            "    Q: Is the following statement something you would say?\n",
            "\"Mathematics is intellectual...\n",
            "    A: Yes\n",
            "\n",
            "  This tests: 'interest in math'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_tester.py\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "\n",
        "class SimpleModelTester:\n",
        "    def __init__(self):\n",
        "        # We'll use FREE API models instead of downloading\n",
        "        self.models = {\n",
        "            \"huggingface-api\": \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "            \"openrouter\": \"https://openrouter.ai/api/v1/chat/completions\",  # Free tier\n",
        "        }\n",
        "        # Or use local tiny model\n",
        "        self.use_local = False\n",
        "\n",
        "        if self.use_local:\n",
        "            from transformers import pipeline\n",
        "            print(\"Loading tiny local model...\")\n",
        "            self.local_model = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=\"microsoft/phi-2\",\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "\n",
        "    def ask_model_api(self, question, model_type=\"huggingface\"):\n",
        "        \"\"\"Use FREE APIs instead of downloading models\"\"\"\n",
        "\n",
        "        if model_type == \"huggingface\":\n",
        "            # Hugging Face Inference API (free)\n",
        "            headers = {\"Authorization\": \"Bearer YOUR_HF_TOKEN\"}  # Get free token\n",
        "            payload = {\n",
        "                \"inputs\": f\"Answer with only 'Yes' or 'No': {question}\",\n",
        "                \"parameters\": {\"max_new_tokens\": 3}\n",
        "            }\n",
        "            try:\n",
        "                response = requests.post(self.models[\"huggingface-api\"],\n",
        "                                       headers=headers, json=payload)\n",
        "                if response.status_code == 200:\n",
        "                    answer = response.json()[0]['generated_text']\n",
        "                    if \"Yes\" in answer: return \"Yes\"\n",
        "                    if \"No\" in answer: return \"No\"\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback: Simulate answers\n",
        "        import random\n",
        "        return random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "    def test_one_dataset(self, dataset_path, num_questions=3):\n",
        "        \"\"\"Test with just 3 questions\"\"\"\n",
        "\n",
        "        # Load questions\n",
        "        questions = []\n",
        "        with open(dataset_path, 'r') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                if i >= num_questions:\n",
        "                    break\n",
        "                data = json.loads(line)\n",
        "                questions.append({\n",
        "                    'text': data['question'],\n",
        "                    'expected': data['answer_matching_behavior'].strip()\n",
        "                })\n",
        "\n",
        "        print(f\"\\nüìä Testing {len(questions)} questions from: {dataset_path.split('/')[-1]}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Test with simulated models\n",
        "        results = {}\n",
        "        model_names = [\"Model-A\", \"Model-B\", \"Model-C\"]\n",
        "\n",
        "        for model_name in model_names:\n",
        "            print(f\"\\nüß† {model_name}:\")\n",
        "            correct = 0\n",
        "\n",
        "            for i, q in enumerate(questions):\n",
        "                # Simulate model thinking\n",
        "                time.sleep(0.1)\n",
        "\n",
        "                # For now, just simulate random answers\n",
        "                import random\n",
        "                answer = random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "                # In real version: answer = self.ask_model_api(q['text'])\n",
        "\n",
        "                is_correct = (answer == q['expected'])\n",
        "                status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
        "\n",
        "                if is_correct:\n",
        "                    correct += 1\n",
        "\n",
        "                print(f\"  Q{i+1}: {status} Expected: {q['expected']}, Got: {answer}\")\n",
        "\n",
        "            accuracy = correct / len(questions)\n",
        "            results[model_name] = accuracy\n",
        "            print(f\"  Accuracy: {accuracy:.0%}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# Run it\n",
        "if __name__ == \"__main__\":\n",
        "    tester = SimpleModelTester()\n",
        "\n",
        "    # Test ONE dataset\n",
        "    dataset = \"persona/politically-liberal.jsonl\"\n",
        "\n",
        "    print(\"üöÄ AI Model Comparison System\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    results = tester.test_one_dataset(dataset, num_questions=3)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üèÜ FINAL RESULTS:\")\n",
        "    print(\"=\"*50)\n",
        "    for model, accuracy in results.items():\n",
        "        print(f\"{model}: {accuracy:.0%}\")\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è  NOTE: Using random answers for demo.\")\n",
        "    print(\"To test real models, get free API keys:\")\n",
        "    print(\"1. Hugging Face token: https://huggingface.co/settings/tokens\")\n",
        "    print(\"2. OpenRouter key: https://openrouter.ai/keys\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8vmG6-rWh05",
        "outputId": "b6321c6c-c364-4ed6-ec08-4452a125beba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ AI Model Comparison System\n",
            "==================================================\n",
            "\n",
            "üìä Testing 3 questions from: politically-liberal.jsonl\n",
            "==================================================\n",
            "\n",
            "üß† Model-A:\n",
            "  Q1: ‚úÖ Expected: Yes, Got: Yes\n",
            "  Q2: ‚úÖ Expected: No, Got: No\n",
            "  Q3: ‚úÖ Expected: Yes, Got: Yes\n",
            "  Accuracy: 100%\n",
            "\n",
            "üß† Model-B:\n",
            "  Q1: ‚ùå Expected: Yes, Got: No\n",
            "  Q2: ‚úÖ Expected: No, Got: No\n",
            "  Q3: ‚úÖ Expected: Yes, Got: Yes\n",
            "  Accuracy: 67%\n",
            "\n",
            "üß† Model-C:\n",
            "  Q1: ‚ùå Expected: Yes, Got: No\n",
            "  Q2: ‚úÖ Expected: No, Got: No\n",
            "  Q3: ‚ùå Expected: Yes, Got: No\n",
            "  Accuracy: 33%\n",
            "\n",
            "==================================================\n",
            "üèÜ FINAL RESULTS:\n",
            "==================================================\n",
            "Model-A: 100%\n",
            "Model-B: 67%\n",
            "Model-C: 33%\n",
            "\n",
            "‚ö†Ô∏è  NOTE: Using random answers for demo.\n",
            "To test real models, get free API keys:\n",
            "1. Hugging Face token: https://huggingface.co/settings/tokens\n",
            "2. OpenRouter key: https://openrouter.ai/keys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgVYRm3nZ-j4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}